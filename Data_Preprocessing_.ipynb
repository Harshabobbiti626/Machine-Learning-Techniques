{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1cOjNd9tQVHXG2h-DCkwvnSn0b7YdoKm_",
      "authorship_tag": "ABX9TyPz1KdEjxaoXQW3vu2g55dY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Harshabobbiti626/Machine-Learning-Techniques/blob/main/Data_Preprocessing_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Preprocessing#"
      ],
      "metadata": {
        "id": "f7t6iumq98nM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data preprocessing is the process of cleaning and preparing the raw data so that it can be used in a machine learning model. It's the first step in creating a machine learning model, and it's essential for getting the most accurate results.When working with data, it's important to clean it up and make it easy to read before doing any other operations. This is done through the use of data preprocessing tasks.\n",
        "\n",
        "**STEPS INVOLVED IN DOING:**\n",
        "\n",
        "-Getting the dataset\n",
        "\n",
        "-Importing libraries\n",
        "\n",
        "-Importing datasets\n",
        "\n",
        "-Finding Missing Data\n",
        "\n",
        "-Encoding Categorical Data\n",
        "\n",
        "-Splitting dataset into training and test set\n",
        "\n",
        "-Feature scaling"
      ],
      "metadata": {
        "id": "FQAJd-6I-A_O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# importing libraries  \n",
        "import numpy as nm  \n",
        "import matplotlib.pyplot as mtp  \n",
        "import pandas as pd  \n",
        "from sklearn.impute import SimpleImputer\n",
        "  \n",
        "#importing datasets  \n",
        "data_set= pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Machine Learning datasets/Preprocessing_Data.csv')  "
      ],
      "metadata": {
        "id": "RdYoTAJgCHg6"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Extracting Independent and Dependent Variable  \n",
        "x= data_set.iloc[:, :-1].values  \n",
        "y= data_set.iloc[:, 3].values  "
      ],
      "metadata": {
        "id": "f5vfCxjZC2VO"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#handling missing data (Replacing missing data with the mean value)  \n",
        "imputer= SimpleImputer(missing_values=nm.nan, strategy='mean')\n",
        "\n",
        "#Fitting imputer object to the independent variables x.   \n",
        "imputerimputer= imputer.fit(x[:, 1:3])  \n",
        "#Replacing missing data with the calculated mean value  \n",
        "x[:, 1:3]= imputer.transform(x[:, 1:3])  "
      ],
      "metadata": {
        "id": "jwgsm66hDEiW"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Catgorical data  \n",
        "#for Country Variable  \n",
        "from sklearn.preprocessing import LabelEncoder  \n",
        "label_encoder_x= LabelEncoder()  \n",
        "x[:, 0]= label_encoder_x.fit_transform(x[:, 0])  "
      ],
      "metadata": {
        "id": "1gDCSyE4H6cC"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#for Country Variable  \n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder  \n",
        "label_encoder_x= LabelEncoder()  \n",
        "x[:, 0]= label_encoder_x.fit_transform(x[:, 0])  "
      ],
      "metadata": {
        "id": "iM1xG1T9JEcg"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Encoding for dummy variables  \n",
        "onehot_encoder= OneHotEncoder(handle_unknown='ignore')  \n",
        "x= onehot_encoder.fit_transform(x).toarray() "
      ],
      "metadata": {
        "id": "ozep9OOlJUOH"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#encoding for purchased variable  \n",
        "labelencoder_y= LabelEncoder()  \n",
        "y= labelencoder_y.fit_transform(y)  "
      ],
      "metadata": {
        "id": "TdSMvsuVLDn9"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting the dataset into training and test set.  \n",
        "from sklearn.model_selection import train_test_split  \n",
        "x_train, x_test, y_train, y_test= train_test_split(x, y, test_size= 0.2, random_state=0)  "
      ],
      "metadata": {
        "id": "cryQz0Q4LP3h"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Feature Scaling of datasets  \n",
        "from sklearn.preprocessing import StandardScaler  \n",
        "st_x= StandardScaler()  \n",
        "x_train= st_x.fit_transform(x_train)  \n",
        "x_test= st_x.transform(x_test)  "
      ],
      "metadata": {
        "id": "uL821HdbLTWX"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"X_train:\",x_train)"
      ],
      "metadata": {
        "id": "1zvH1d6dLUXo",
        "outputId": "7cb59121-0363-4ec5-a7ac-044990cb4b2f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train: [[-1.          2.64575131 -0.77459667 -0.37796447  0.         -0.37796447\n",
            "  -0.37796447 -0.37796447 -0.37796447  2.64575131 -0.37796447 -0.37796447\n",
            "   0.         -0.37796447 -0.37796447  0.         -0.37796447 -0.37796447\n",
            "   2.64575131 -0.37796447 -0.37796447 -0.37796447  0.        ]\n",
            " [ 1.         -0.37796447 -0.77459667 -0.37796447  0.         -0.37796447\n",
            "   2.64575131 -0.37796447 -0.37796447 -0.37796447 -0.37796447 -0.37796447\n",
            "   0.         -0.37796447 -0.37796447  0.         -0.37796447 -0.37796447\n",
            "  -0.37796447  2.64575131 -0.37796447 -0.37796447  0.        ]\n",
            " [-1.         -0.37796447  1.29099445  2.64575131  0.         -0.37796447\n",
            "  -0.37796447 -0.37796447 -0.37796447 -0.37796447 -0.37796447 -0.37796447\n",
            "   0.          2.64575131 -0.37796447  0.         -0.37796447 -0.37796447\n",
            "  -0.37796447 -0.37796447 -0.37796447 -0.37796447  0.        ]\n",
            " [-1.         -0.37796447  1.29099445 -0.37796447  0.         -0.37796447\n",
            "  -0.37796447 -0.37796447  2.64575131 -0.37796447 -0.37796447 -0.37796447\n",
            "   0.         -0.37796447  2.64575131  0.         -0.37796447 -0.37796447\n",
            "  -0.37796447 -0.37796447 -0.37796447 -0.37796447  0.        ]\n",
            " [ 1.         -0.37796447 -0.77459667 -0.37796447  0.         -0.37796447\n",
            "  -0.37796447 -0.37796447 -0.37796447 -0.37796447 -0.37796447  2.64575131\n",
            "   0.         -0.37796447 -0.37796447  0.         -0.37796447 -0.37796447\n",
            "  -0.37796447 -0.37796447 -0.37796447  2.64575131  0.        ]\n",
            " [-1.         -0.37796447  1.29099445 -0.37796447  0.         -0.37796447\n",
            "  -0.37796447  2.64575131 -0.37796447 -0.37796447 -0.37796447 -0.37796447\n",
            "   0.         -0.37796447 -0.37796447  0.         -0.37796447  2.64575131\n",
            "  -0.37796447 -0.37796447 -0.37796447 -0.37796447  0.        ]\n",
            " [ 1.         -0.37796447 -0.77459667 -0.37796447  0.         -0.37796447\n",
            "  -0.37796447 -0.37796447 -0.37796447 -0.37796447  2.64575131 -0.37796447\n",
            "   0.         -0.37796447 -0.37796447  0.         -0.37796447 -0.37796447\n",
            "  -0.37796447 -0.37796447  2.64575131 -0.37796447  0.        ]\n",
            " [ 1.         -0.37796447 -0.77459667 -0.37796447  0.          2.64575131\n",
            "  -0.37796447 -0.37796447 -0.37796447 -0.37796447 -0.37796447 -0.37796447\n",
            "   0.         -0.37796447 -0.37796447  0.          2.64575131 -0.37796447\n",
            "  -0.37796447 -0.37796447 -0.37796447 -0.37796447  0.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"x_test:\",x_test)"
      ],
      "metadata": {
        "id": "pn3dI9kgLfz5",
        "outputId": "fa888e29-7b1f-42af-83bb-0a7190efcd62",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_test: [[-1.          2.64575131 -0.77459667 -0.37796447  1.         -0.37796447\n",
            "  -0.37796447 -0.37796447 -0.37796447 -0.37796447 -0.37796447 -0.37796447\n",
            "   0.         -0.37796447 -0.37796447  1.         -0.37796447 -0.37796447\n",
            "  -0.37796447 -0.37796447 -0.37796447 -0.37796447  0.        ]\n",
            " [-1.          2.64575131 -0.77459667 -0.37796447  0.         -0.37796447\n",
            "  -0.37796447 -0.37796447 -0.37796447 -0.37796447 -0.37796447 -0.37796447\n",
            "   1.         -0.37796447 -0.37796447  0.         -0.37796447 -0.37796447\n",
            "  -0.37796447 -0.37796447 -0.37796447 -0.37796447  1.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EIJcXz8fMRSz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}